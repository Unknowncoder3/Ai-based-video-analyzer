
# ğŸ¥ AI-Based Video Analyzer

> **Offline multimodal video intelligence powered by state-of-the-art open-source AI.**
>
> Extract speech, understand visuals, and generate intelligent summaries from videos â€” all locally, with zero paid APIs.

---

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.9%2B-blue" />
  <img src="https://img.shields.io/badge/Streamlit-App-red" />
  <img src="https://img.shields.io/badge/Whisper-ASR-green" />
  <img src="https://img.shields.io/badge/BLIP-Image%20Captioning-purple" />
  <img src="https://img.shields.io/badge/Ollama-LLM-orange" />
  <img src="https://img.shields.io/badge/License-MIT-brightgreen" />
</p>

---

## ğŸ“Œ Overview

**AI-Based Video Analyzer** is an end-to-end multimodal AI system that converts raw video files into structured, meaningful insights. It integrates **speech recognition**, **computer vision**, and **large language models** into a single pipeline â€” designed to run completely **offline** for maximum privacy and control.

This project demonstrates real-world application of modern AI systems and is ideal for **research, content analysis, and production-grade prototyping**.

---

## âœ¨ Key Features

- ğŸ§ **Automatic Speech Transcription**  
  Converts video audio into accurate text using OpenAI Whisper (local execution).

- ğŸ–¼ï¸ **Visual Frame Understanding**  
  Samples video frames and generates contextual captions using BLIP.

- ğŸ§  **LLM-Powered Semantic Summaries**  
  Combines audio and visual insights to generate coherent summaries via Mistral (Ollama).

- â±ï¸ **Timestamped Insights**  
  Visual captions aligned with timestamps for better interpretability.

- ğŸ”’ **Local-First & Privacy-Focused**  
  No cloud APIs, no data leakage â€” everything runs on your machine.

- ğŸ’» **Interactive Web Interface**  
  Streamlit-based UI for smooth uploads, analysis, and result visualization.

---

## ğŸ§  Architecture (High-Level)

```

Video Input
â”‚
â”œâ”€â”€â–º Audio Extraction â”€â”€â–º Whisper ASR â”€â”€â–º Transcript
â”‚
â”œâ”€â”€â–º Frame Sampling â”€â”€â–º BLIP â”€â”€â–º Visual Captions
â”‚
â””â”€â”€â–º Transcript + Captions â”€â”€â–º LLM (Mistral via Ollama) â”€â”€â–º Summary

````

---

## ğŸ–¼ï¸ Application Screenshots 
### ğŸ“¤ Video Upload & Configuration ![Video Upload](screenshots/first.jpeg) 
--- 
### ğŸ—£ï¸ Speech Transcription Output ![Transcription](screenshots/second.jpeg) 
--- 
### ğŸ§  AI-Generated Summary ![Summary](screenshots/third.jpeg) 
--- 
### ğŸ•’ Timeline-Based Caption Analysis ![Timeline](screenshots/fourth.jpeg) 
---

---

## âš™ï¸ System Requirements

- Python **3.9+**
- FFmpeg installed and added to PATH
- 8GB+ RAM recommended
- GPU optional (improves performance)

---

## ğŸš€ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Unknowncoder3/Ai-based-video-analyzer.git
cd Ai-based-video-analyzer
````

### 2ï¸âƒ£ Create & Activate Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ§  Install & Run Ollama (LLM Backend)

```bash
ollama pull mistral
ollama serve
```

> **Why Ollama?**
> Enables fast, local execution of LLMs without relying on paid APIs.

---

## â–¶ï¸ Run the Application

```bash
streamlit run app.py
```

---

## ğŸ§ª How to Use

1. Upload a video file (MP4 / MOV / MKV / AVI)
2. Click **Analyze Video**
3. View:

   * Speech transcription
   * AI-generated semantic summary
   * Timestamped visual captions
4. Review or download extracted insights

---

## ğŸ“ˆ Use Cases

* ğŸ¥ Video content summarization
* ğŸ§‘â€ğŸ« Lecture & tutorial analysis
* ğŸ¤ Interview & meeting review
* ğŸ§  Multimodal AI demonstrations
* ğŸ“Š Media intelligence & research workflows

---

## ğŸ”® Future Enhancements

* Scene change detection
* Speaker diarization
* Emotion & sentiment analysis
* Batch video processing
* Timestamp-level summaries

---

## ğŸ‘¤ Author

**Snehasish Das**
Final Year CSBS Student | AI & Python Developer

* GitHub: [https://github.com/Unknowncoder3](https://github.com/Unknowncoder3)
* LinkedIn: [https://www.linkedin.com/in/snehasish-das-7a9803219](https://www.linkedin.com/in/snehasish-das-7a9803219)

---

## â­ Support

If you find this project useful, please â­ **star the repository** â€” it helps improve visibility and motivates future development.

---

## ğŸ“„ License

This project is licensed under the **MIT License**.


